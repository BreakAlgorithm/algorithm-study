# 2주차 개념정리

목차

- [셸 정렬(shell sort)](#셸-정렬shell-sort)<br>
- [퀵 정렬(quick sort)](#퀵-정렬quick-sort)
- [합병 정렬 or 병합 정렬(merge sort)](#합병-정렬-or-병합-정렬merge-sort)
- [참고자료](#참고자료)

2주차는 셸, 퀵, 합병 정렬을 공부 및 구현하고 알고리즘 문제는 백준의 [1181: 단어정렬](https://www.acmicpc.net/problem/1181)과 [10814: 나이순 정렬](https://www.acmicpc.net/problem/10814)을 각자 풀기로 했다. 

먼저 쉘 정렬부터 알아보자.

## 셸 정렬(shell sort)

**개념 및 설명**

> 가장 오래된 정렬 알고리즘의 하나로, 'Donald L. Shell'이 제안한 방식이다.
>
> 삽입 정렬의 성질을 이용, 보완한 삽입정렬의 일반화로 볼 수 있다.
>
> 주어진 자료 리스트를 특정 매개변수 값의 길이를 갖는 부파일(subfile)로 쪼개서, 각 부파일에서 정렬을 수행한다.

**작동 방식**

- 정렬해야 할 리스트의 각 k번째 요소를 추출해서 부분 리스트를 만든다. 이때, k를 '간격(gap)'이라고 한다.
  - 간격의 초깃값: (정렬할 값의 수) / 2
  - 생성된 부분 리스트의 개수는 gap과 같다.
- 각 회전마다 간격 k를 절반으로 줄인다. 즉, 각 회전이 반복될 때마다 하나의 부분 리스트에 속한 값들의 개수는 증가한다.
  - 간격은 홀수로 하는 것이 좋다.
  - 간격을 절반으로 줄일 때 짝수가 나오면 +1을 해서 홀수로 만든다.
- 간격 k가 1이 될 때까지 반복한다.(1이되면 일반적인 insertion sort를 전체 배열에 진행한다.)

글만 봐서는 헷갈릴 수 있으므로 아래의 그림을 살펴보자.

![shellsort1회](/Users/kim/Desktop/MyPrivateRepo/velog/algorithm/study_2주차/shellsort1회.png)

![shellsort2회](/Users/kim/Desktop/MyPrivateRepo/velog/algorithm/study_2주차/shellsort2회.png)

![shellsort3회](/Users/kim/Desktop/MyPrivateRepo/velog/algorithm/study_2주차/shellsort3회.png)

**코드**

```c
// c
void shellSort(int *arr, int n) {
  int k = 2, gap = n / k, key, j; // 보편적으로 나누는 그룹수(k)는 2로 뒀다.
  while( gap > 0) {
    for(int i = gap; i< n; i++) {
      key = arr[i]; // 현재 삽입될 숫자
      j = i;
      // 삽입정렬 실행
      while( j >= gap && arr[j - gap] > key){
        arr[j] = arr[j - gap];
        j -= gap;
      }
      arr[j] = key;
    }
    gap /= k;
  }
}
```

```python
# python
def Shellsort(arr,h):
    for i in range(h,len(arr)):
        k=i-h
        key=arr[i]
        while k>=0 and key < arr[k]:
            arr[k+h] = arr[k]
            k=k-h
        arr[k+h] = key
    return arr
```

**장점**

- 연속적이지 않은 부분 리스트에서 자료의 교환이 일어나면 더 큰 거리를 이동한다. 즉, 최종 위치에 있을 가능성이 높아진다.(작은 값과 먼 거리의 큰 값이 교환되므로)
- 부분 리스트는 어느 정도 정렬이 된 상태이기 때문에 부분 리스트의 개수가 1이 되게 되면 셸 정렬은 기본적으로 삽입 정렬을 수행하는 것이지만 삽입 정렬보다 더욱 빠르게 수해오딘다.
- 알고리즘이 간단하여 쉽게 구현할 수 있다.

**단점**

- 불안정 정렬이다(같은 값이 어떤 부분 리스트에 속하냐에 따라 위치가 바뀔 수 있음)

  - ex) 5(1) 5(2) 1 7 -> 1 5(2) 5(1) 7이 될 수 있음

- 간격을 어떻게 정하냐에 따라 성능 차이가 크다.

  

### 시간 복잡도

n은 원소의 총 개수

- **최선의 경우(정렬된 경우)**
  - O(n)
- **최악의 경우**
- **평균**
  - gap에 의존한다. 하지만 보통 O(n<sup>1.5</sup>)로 보는 곳이 많은 것 같다.

### 공간 복잡도

- 전체는 O(n)이고 O(1)의 보조 공간이므로 즉 in-place(제자리) 정렬이다.

영어를 잘 한다면 위키피디아나 아래의 자료들을 읽어보면 좋을 것 같다.

- [Shellsort 위키피디아](https://en.wikipedia.org/wiki/Shellsort#cite_note-KR-7)
- [Fastest gap Sequence for shell sort?](https://stackoverflow.com/questions/2539545/fastest-gap-sequence-for-shell-sort)
- [Analysis of Shellsort and Related Algorithms - by Sedgewick](https://www.cs.princeton.edu/~rs/shell/paperF.pdf)

## 퀵 정렬(quick sort)

**개념 및 설명**

> '찰스 앤터니 리처드 호어'가 개발한 정렬 알고리즘이다.
>
> `불안정 정렬`에 속하며, 다른 원소와의 비교만으로 정렬을 수행하는 비교 정렬에 속한다.
>
> 분할 정복 알고리즘의 하나로, 평균적으로 `매우 빠른 수행 속도`를 자랑한다.
>
> 매 단계에서 적어도 1개의 원소가 자기 자리를 찾게 되므로 이후 정렬할 개수가 줄어든다. 따라서, 다른 O(n log n) 알고리즘에 비해 훨씬 빠르게 동작한다.

**작동 방식**

1. 리스트 가운데서 하나의 원소(**피벗(pivot)**이라 함)를 고른다.
2. 피벗 앞에는 피벗보다 값이 작은 모든 원소들이 오고, 피벗 뒤에는 피벗보다 값이 큰 모든 원소들이 오도록 피벗을 기준으로 리스트를 둘로 나눈다. 이를 **분할**이라고 한다. 분할을 마친 뒤에 피벗은 더 이상 움직이지 않는다.
3. 분할된 두 개의 작은 리스트에 대해 **재귀**적으로 이 과정을 반복한다. 재귀는 리스트의 크기가 0이나 1이 될때까지 반복된다.

**코드**

```c
// c언어
void quickSort(int arr[], int left, int right) {
      int i = left, j = right;
      int pivot = arr[(left + right) / 2];
      int temp;
      do
      {
        while (arr[i] < pivot)
            i++;
        while (arr[j] > pivot)
            j--;
        if (i<= j)
        {
            temp = arr[i];
            arr[i] = arr[j];
            arr[j] = temp;
            i++;
            j--;
        }
      } while (i<= j);

    /* recursion */
    if (left < j)
        quickSort(arr, left, j);

    if (i < right)
        quickSort(arr, i, right);
}
```

```c
// c++
inline void swap(int &a, int &b){
    int t = a; a = b; b = t;
}

void quickSort(int A[], int low, int high) {
    if(low >= high) return; // base condition

    // divide process
    int i = low-1, j = low;
    int&pivot = A[high];
    for (; j < high; ++j) {
        if ( A[j] < pivot)
            swap(A[++i], A[j]);
    }
    swap(A[++i], pivot);

    // conquer process
    quickSort(A, low, i-1);
    quickSort(A, i+1, high);
}
```

```python
# python
def quicksort(x):
    if len(x) <= 1:
        return x

    pivot = x[len(x) // 2]
    less = []
    more = []
    equal = []
    for a in x:
        if a < pivot:
            less.append(a)
        elif a > pivot:
            more.append(a)
        else:
            equal.append(a)

    return quicksort(less) + equal + quicksort(more)
```

**장점**

- 속도가 빠르다.
- 추가 메모리 공간을 필요로 하지 않는다.

**단점**

- 정렬된 리스트에 대해서는 퀵 정렬의 불균형 분할에 의해 오히려 수행시간이 더 많이 걸린다.

  -> 퀵 정렬의 불균형 분할을 방지하기 위하여 피벗을 선택할 때 더욱 리스트를 균등하게 분할할 수 있는 데이터를 선택한다.

  -> 기초적인 방법으로는 난수 분할이 사용되는데 안정성이 떨어진다. 따라서 많은 라이브러리에서는 세 값(좌측 끝, 중앙, 우측 끝)의 중위법을 이용하여 분할한다. 이 방법을 사용하면 중앙에서 분할될 가능성이 높아 전체적으로 정렬의 성능이 좋아진다.

### 시간 복잡도

n은 원소의 총 개수

- **최선의 경우**
  - 비교 횟수
    - 순환 호출의 깊이
      - 피벗이 중앙에 있어서 계속 2로 균등하게 나눠서 n/2 -> n/4 -> n/8 이런식으로 진행될 때이다.
      - 이때, n/x=1이 될때까지 반복하게 된다.(즉, x가 n이 될 때이다.)
      - 이때 ,x는 2<sup>k</sup>로 볼 수 있는데 양변에 log<sub>2</sub>를 취하면 k = log<sub>2</sub>x이고 x가 n이 될때 종료되므로 k = log<sub>2</sub>n임을 알 수 있다.
    - 각 순환 호출 단계의 비교 연산
      - 각 순환 호출에서는 전체 리스트의 대부분의 레코드를 비교해야 하므로 평균 n번 정도의 비교가 이루어진다.
      - 즉, 처음 분할 됐을 때 {n/2}, {n/2}인데 각각의 부분 배열에서 n/2번 비교가 일어나므로 결론적으로는 n번 일어나는 것이다.
    - 순환 호출의 깊이 * 각 순환 호출 단계의 비교 연산 **nlog<sub>2</sub>n**임을 알 수 있다.
  - 이동 횟수
    - 비교 횟수보다 적으므로 무시할 수 있다.
  - Best T(n) = O(nlog<sub>2</sub>n)
- **최악의 경우**
  - 리스트가 계속 불균형하게 나누어지는 경우이다.
  - 비교 횟수
    - 순환 호출의 깊이
      - 1개 (n-1)개 이런식으로 나누어질 때 n번 나눠져야 한다.
      - 즉, 깊이는 n이다.
    - 각 순환 호출 단계의 비교 연산
      - 각 순환 호출에서는 전체 리스트의 대부분의 레코드를 비교해야 하므로 평균 n번 정도의 비교가 이루어진다.
      - 평균 n번
    - 순환 호출의 깊이 * 각 순환 호출 단계의 비교 연산 = n<sup>2</sup>
  - 이동 횟수
    - 비교 횟수보다 적으므로 무시할 수 있다.
  - Worst T(n) = O(n<sup>2</sup>)

## 합병 정렬 or 병합 정렬(merge sort)

**개념 및 설명**

> '존 폰 노이만(John von Neumann)'이 제안한 방법
>
> O(nlongn) 비교 기반 정렬 알고리즘이다.
>
> **안정 정렬**에 속하며, 분할 정복 알고리즘의 하나이다.

**작동 방식**

1. 리스트의 길이가 0 또는 1이면 이미 정렬된 것으로 본다. 아닐 경우
2. (분할: divide) 정렬되지 않은 리스트를 절반으로 잘라 비슷한 크기의 두 부분 리스트로 나눈다.
3. (정복:conquer) 각 부분 리스트를 재귀적으로 합병 정렬을 이용해 정렬한다.
4. (결합:combine) 두 부분 리스트를 다시 하나의 정렬된 리스트로 합병한다.

<a title="Swfung8 / CC BY-SA (https://creativecommons.org/licenses/by-sa/3.0)" href="https://commons.wikimedia.org/wiki/File:Merge-sort-example-300px.gif"><img width="256" alt="Merge-sort-example-300px" src="https://upload.wikimedia.org/wikipedia/commons/c/cc/Merge-sort-example-300px.gif"></a>

by - Swfung8 / CC BY-SA (https://creativecommons.org/licenses/by-sa/3.0)

**코드**

**탑다운**은 재귀를 이용해 리스트가 1이 될 때까지 반으로 계속 쪼개 나가는 방법

**바텀업**은 1개씩 정렬, 2개씩 정렬, 4개씩 정렬을 반복해나가는 방법이다.

[Non-recursive merge sort with two nested loops - how?](https://stackoverflow.com/questions/7761974/non-recursive-merge-sort-with-two-nested-loops-how)의 그림과 설명을 참고하면 도움이 될 것 같다.

https://johngrib.github.io/wiki/merge-sort/

```c
// c언어 top - down
/// merge sort range : [low ~ high]
void mergeSort(int A[], int low, int high, int B[]){
    // 1. base condition
    if(low >= high) return;

    // 2. divide
    int mid = (low + high) / 2;

    // 3. conquer
    mergeSort(A, low, mid, B);
    mergeSort(A, mid+1, high, B);

    // 4. combine
    int i=low, j=mid+1, k=low;
    for(;k<=high;++k){
        if(j > high ) B[k] = A[i++];
        else if(i > mid) B[k] = A[j++];
        else if(A[i] < A[j]) B[k] = A[i++];
        else B[k] = A[j++];
    }

    // 5. copy
    for(i=low;i<=high;++i) A[i] = B[i];
}
```

```c
// c bottom up
// array A[] has the items to sort; array B[] is a work array
void BottomUpMergeSort(A[], B[], n)
{
    // Each 1-element run in A is already "sorted".
    // Make successively longer sorted runs of length 2, 4, 8, 16... until whole array is sorted.
    for (width = 1; width < n; width = 2 * width)
    {
        // Array A is full of runs of length width.
        for (i = 0; i < n; i = i + 2 * width)
        {
            // Merge two runs: A[i:i+width-1] and A[i+width:i+2*width-1] to B[]
            // or copy A[i:n-1] to B[] ( if(i+width >= n) )
            BottomUpMerge(A, i, min(i+width, n), min(i+2*width, n), B);
        }
        // Now work array B is full of runs of length 2*width.
        // Copy array B to array A for next iteration.
        // A more efficient implementation would swap the roles of A and B.
        CopyArray(B, A, n);
        // Now array A is full of runs of length 2*width.
    }
}

//  Left run is A[iLeft :iRight-1].
// Right run is A[iRight:iEnd-1  ].
void BottomUpMerge(A[], iLeft, iRight, iEnd, B[])
{
    i = iLeft, j = iRight;
    // While there are elements in the left or right runs...
    for (k = iLeft; k < iEnd; k++) {
        // If left run head exists and is <= existing right run head.
        if (i < iRight && (j >= iEnd || A[i] <= A[j])) {
            B[k] = A[i];
            i = i + 1;
        } else {
            B[k] = A[j];
            j = j + 1;
        }
    }
}

void CopyArray(B[], A[], n)
{
    for(i = 0; i < n; i++)
        A[i] = B[i];
}
```

[Mergesort - Is Bottom-Up faster than Top-Down](https://stackoverflow.com/questions/10153393/mergesort-is-bottom-up-faster-than-top-down)을 보면 Bottom-up이 좀 더 적은 연산을 사용한다고 되어 있다.

**장점**

- 안정적인 정렬 방법이다.
- 만약 레코드를 연결 리스트(Linked List)로 구성하면, 링크 인덱스만 변경되므로 데이터의 이동은 무시할 수 있을 정도로 작아진다.
  - 제자리 정렬(in-place sorting)로 구현할 수 있다.
- 따라서 크기가 큰 레코드를 정렬할 경우에 연결 리스트를 사용한다면, 합병 정렬은 퀵 정렬을 포함한 다른 어떤 정렬 방법보다 효율적이다.

**단점**

- 만약 레코드를 배열(Array)로 구성하면, 임시 배열이 필요하다.
  - 제자리 정렬(in-place sorting)이 아니다.
- 레코드들의 크기가 큰 경우에는 이동 횟수가 많으므로 매우 큰 시간적 낭비를 초래한다.

### 시간 복잡도

- **분할 단계**
  - 비교 연산과 이동 연산이 수행되지 않는다.
- **합병 단계**
  - 비교 횟수
    - 순환 호출의 깊이(합병 단계 수)
      - 1개에서 계속 *2를 하며 합쳐지므로 깊이는 log<sub>2</sub>n임을 알 수 있다.
    - 각 합병 단계의 비교 연산은 총 원소의 수인 n개이다.
    - 순환 호출의 깊이 만큼의 합병 단계 * 각 합병 단계의 비교 연산 = **nlog<sub>2</sub>n**이다.
  - 이동 횟수
    - 순환 호출의 깊이(합병 단계 수)
      - log<sub>2</sub>n
    - 각 합병 단계의 이동 연산
      - 임시 배열에 복사했다가 다시 가져와야되므로 이동 연산은 총 부분 배열에 들어 있는 요소의 개수가 n인 경우, 레코드의 이동이 2n번 발생한다.
      - 순환 호출의 깊이 만큼의 합병 단계 * 각 합병 단계의 이동 연산 = **2nlog<sub>2</sub>n**
  - Best T(n) = Worst T(n) = Avg T(n) = 2log<sub>2</sub>n(비교) + 2nlog<sub>2</sub>n(이동) = 3nlog<sub>2</sub>n = **O(nlog<sub>2</sub>n)



---

## <a id ="ref"></a>참고자료

- [위키피디아](https://ko.wikipedia.org/wiki/%EC%A0%95%EB%A0%AC_%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98)
- [HeeJeong Kwon님 블로그](https://gmlwjd9405.github.io/)
- [Stackoverflow](https://stackoverflow.com/)
